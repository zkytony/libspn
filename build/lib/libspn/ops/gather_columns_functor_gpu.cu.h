#ifndef THIRD_PARTY_TENSORFLOW_CORE_KERNELS_GATHER_COLUMNS_FUNCTOR_GPU_CU_H_
#define THIRD_PARTY_TENSORFLOW_CORE_KERNELS_GATHER_COLUMNS_FUNCTOR_GPU_CU_H_

#if GOOGLE_CUDA

#define EIGEN_USE_GPU

#include "gather_columns_functor.h"
#include "tensorflow/core/framework/register_types.h"
#include "tensorflow/core/platform/types.h"
#include "tensorflow/core/util/cuda_kernel_helper.h"

namespace tensorflow
{
typedef Eigen::GpuDevice GPUDevice;

template <typename T, typename IndT>
__global__ void GatherColumnsOpKernel(const T* params, const IndT* indices,
                                      int64 params_cols, int64 indices_size,
                                      int64 output_size, T* output)
{
  CUDA_1D_KERNEL_LOOP(i, output_size)
  {
    int row = i / indices_size;
    int col = i % indices_size;

    IndT ind_col = ldg(indices + col);
    output[i] = ldg(params + (row * params_cols) + ind_col);
  }
}

namespace functor
{
template <typename T, typename IndT>
struct GatherColumnsFunctor<GPUDevice, T, IndT>
{
  int64 operator()(const GPUDevice& d, typename TTypes<T>::ConstMatrix params,
                   typename TTypes<IndT>::ConstFlat indices,
                   typename TTypes<T>::Matrix output)
  {
    const int64 output_size = output.size();
    const int64 indices_size = indices.size();
    const int64 params_cols = params.dimension(1);

    // Andrzej: Bounds check has been disabled to improve performance
    // IndT* h_indices = nullptr;
    // h_indices = (IndT*)malloc(indices_size * sizeof(IndT));

    // if (h_indices)
    // {
    //   cudaMemcpy(h_indices, indices.data(), indices_size * sizeof(IndT),
    //              cudaMemcpyDeviceToHost);

    //   for (int c = 0; c < indices_size; c++)
    //   {
    //     //--Check indices[i] âˆˆ (0, params_cols]--//
    //     if (!FastBoundsCheck(h_indices[c], params_cols))
    //     {
    //       free(h_indices);
    //       return c;
    //     }
    //   }
    // }

//--Debugging flag disabled by default--//
#if EXEC_TIME_CALC
    float time_taken;
    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);
    cudaEventRecord(start, 0);
#endif  // EXEC_TIME_CALC

    CudaLaunchConfig config = GetCudaLaunchConfig(output_size, d);
    GatherColumnsOpKernel<T, IndT>
        <<<config.block_count, config.thread_per_block, 0, d.stream()>>>(
        params.data(), indices.data(), params_cols, indices_size, output_size,
        output.data());

//--Debugging flag disabled by default--//
#if EXEC_TIME_CALC
    cudaEventRecord(stop, 0);
    cudaEventSynchronize(stop);
    cudaEventElapsedTime(&time_taken, start, stop);
    cudaEventDestroy(start);
    cudaEventDestroy(stop);
    std::cout << "GPU - Time taken: " << time_taken << " ms" << endl;
#endif  // EXEC_TIME_CALC

    // Andrzej: Bounds check has been disabled to improve performance
    // if (h_indices)
    //   free(h_indices);

    return -1;
  }
};
}  // namespace functor
}  // namespace tensorflow

#endif  // GOOGLE_CUDA

#endif  // THIRD_PARTY_TENSORFLOW_CORE_KERNELS_GATHER_COLUMNS_FUNCTOR_GPU_CU_H_
